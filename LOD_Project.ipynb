{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179b180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyterrier as pt\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec95e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pt.started():\n",
    "  pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b97c4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pt.datasets.get_dataset('irds:cord19/trec-covid')\n",
    "pt_index_path = './indices/cord19'\n",
    "\n",
    "if not os.path.exists(pt_index_path + \"/data.properties\"):\n",
    "  indexer = pt.index.IterDictIndexer(pt_index_path, blocks = True)\n",
    "  index_ref = indexer.index(dataset.get_corpus_iter(),\n",
    "                            fields = ['title', 'doi', 'abstract'],\n",
    "                            meta = ('docno',))\n",
    "else:\n",
    "    index_ref = pt.IndexRef.of(pt_index_path + \"/data.properties\")\n",
    "\n",
    "index = pt.IndexFactory.of(index_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350974ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('~/.ir_datasets/cord19/2020-07-16/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa703eba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bda2dfa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metadata.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d627c4d",
   "metadata": {},
   "source": [
    "Dropping empty autors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b50fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = metadata[metadata['authors'].notna()]\n",
    "metadata = metadata.reset_index()\n",
    "metadata = metadata.drop(columns = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20b076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_abbrev = pd.read_csv('./data/wos_abbrev_table.csv', sep = ';', header = None)\n",
    "journal_abbrev=journal_abbrev.T.set_index(0).T\n",
    "journal_abbrev = journal_abbrev[['full', 'abbrev']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bb41f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.merge(metadata, journal_abbrev, left_on='journal', right_on='abbrev', how='left')\n",
    "metadata['full'] = metadata['full'].fillna(metadata['journal'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f08d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95a72b6",
   "metadata": {},
   "source": [
    "## Splitting the authors into single columns\n",
    "\n",
    "A function to split the author dict up into single columns. To make the retrieval process possible, commas, double spaces and other characters had to be removed without using a complex regex solution (in case a person hat a accent in their name for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b8fd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_authors(n):\n",
    "    # get first n articles\n",
    "    author_uid_df = metadata[['authors', 'cord_uid']][:n]\n",
    "    author_uid_df['authors'] = author_uid_df['authors'].apply(pd.Series)\n",
    "    # stringsplit authors\n",
    "    splitted_authors_df = author_uid_df['authors'].str.split(';', expand=True)\n",
    "    author_uid_df = pd.concat([author_uid_df, splitted_authors_df], axis=1)\n",
    "    # drop the authors (column with multiple authors)\n",
    "    author_uid_df.drop(columns='authors')\n",
    "    # replace the empty column of multiple authors\n",
    "    author_uid_df = author_uid_df.drop(columns='authors')\n",
    "    author_uid_df = author_uid_df.replace('', np.nan).set_index('cord_uid').stack().reset_index(name='author').drop('level_1',1)\n",
    "    author_uid_df['author'] = author_uid_df['author'].str.split(',').str[::-1].str.join(' ')\n",
    "\n",
    "    return author_uid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131bea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_authors(n):\n",
    "    # get first n articles\n",
    "    author_uid_df = metadata[['authors', 'cord_uid']][:n]\n",
    "    author_uid_df['authors'] = author_uid_df['authors'].apply(pd.Series)\n",
    "    # stringsplit authors\n",
    "    splitted_authors_df = author_uid_df['authors'].str.split(';', expand=True)\n",
    "    # concatenate the splitted authors to our dataframe\n",
    "    author_uid_df = pd.concat([author_uid_df, splitted_authors_df], axis=1)\n",
    "    # drop the authors (column with multiple authors)\n",
    "    author_uid_df.drop(columns='authors')\n",
    "    # replace the empty column of multiply authors\n",
    "    author_uid_df = author_uid_df.drop(columns='authors')\n",
    "    author_uid_df = author_uid_df.replace('', np.nan).set_index('cord_uid').stack().reset_index(name='author').drop('level_1',1)\n",
    "    author_uid_df['author'] = author_uid_df['author'].str.split(',').str[::-1].str.join(' ')\n",
    "    author_uid_df['author'] = author_uid_df['author'].str.replace('  ', ' ')\n",
    "    author_uid_df['author'] = author_uid_df['author'].str.lstrip()\n",
    "    merged_data = metadata[['cord_uid', 'title', 'license', 'publish_time', 'full']]\n",
    "    merged_data = author_uid_df.merge(merged_data, on = 'cord_uid')\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a811dd92",
   "metadata": {},
   "source": [
    "### How to work with the API:\n",
    "\n",
    "Basic request:\n",
    "https://api.openalex.org/ + work/authors/venues/insitutions/concecpts + ?filter = + columns.search + Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31025290",
   "metadata": {},
   "outputs": [],
   "source": [
    "tariq = requests.get(\n",
    "    'https://api.openalex.org/authors?filter=display_name.search:Tariq'\n",
    ").json()['results'][0]                     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2521343",
   "metadata": {},
   "source": [
    "## Retrieving author information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d2f678",
   "metadata": {},
   "source": [
    "A function to retrieve all the authors from the metadata's first n documents. It creates a list to call OpenAlex with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602fae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAuthors(n_documents):\n",
    "    author_list = []\n",
    "    for i in range(n_documents):\n",
    "        print(metadata['authors'][i])\n",
    "        if(metadata['authors'][i] != \"nan\"):\n",
    "            authors_split = metadata['authors'][i].split(\";\")\n",
    "            for j in range(len(authors_split)):\n",
    "                authors_split[j] = authors_split[j].replace(',', '')\n",
    "                authors_split[j] = authors_split[j].lstrip()\n",
    "                author_list.append(authors_split[j])\n",
    "        else:\n",
    "            author_list.append(\"\")\n",
    "    return author_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f99de3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gets all splitted authors from the first 500 documents\n",
    "authors = getAuthors(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d939b8",
   "metadata": {},
   "source": [
    "Retrieving the data using OpenAlex. If the author is not found, Empty Name is used as dummy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f0a10e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "author_df = pd.DataFrame()\n",
    "\n",
    "for i in range(len(authors)):\n",
    "    try:\n",
    "        author_information = requests.get(\n",
    "            'https://api.openalex.org/authors?filter=display_name.search:'+authors[i]\n",
    "        ).json()['results'][0]\n",
    "        print('Retrieved:',authors[i])\n",
    "        current_author = pd.DataFrame.from_dict(author_information, orient='index')\n",
    "        current_author = current_author.transpose()\n",
    "        author_df = author_df.append(current_author)\n",
    "        author_df['display_name'] =  author_df['display_name'].str.lstrip()\n",
    "\n",
    "        \n",
    "    except:\n",
    "        print(\"Empty name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eb926c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "author_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ee3ef2",
   "metadata": {},
   "source": [
    "Cleaning up the author data: \n",
    "\n",
    "1. Defining a dataframe\n",
    "2. add the extracted information into our dataframe\n",
    "3. replace special characters in the display name\n",
    "4. add the x_concepts (most common research field of the author according to openalex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b4dfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_data = pd.DataFrame(columns= [['display_name', 'relevance_score', 'works_count', 'cited_by_count', 'last_known_institution', 'x_concepts']])\n",
    "author_data = author_df[['display_name', 'relevance_score', 'works_count', 'cited_by_count', 'last_known_institution', 'x_concepts']]\n",
    "\n",
    "author_data['research_field'] = \"\"\n",
    "author_data = author_data.reset_index()\n",
    "author_data = author_data.drop(columns = 'index')\n",
    "\n",
    "\n",
    "#clean display names again\n",
    "\n",
    "for i in range(len(author_data)):\n",
    "    author_data['display_name'][i] = author_data['display_name'][i].lstrip()\n",
    "\n",
    "for i in range(len(author_data)):\n",
    "    try:\n",
    "        author_data.iloc[i, author_data.columns.get_loc('research_field')] = author_data.iloc[i]['x_concepts'][0]['display_name']\n",
    "    except:\n",
    "        author_data.iloc[i, author_data.columns.get_loc('research_field')] = \"Unknown\"\n",
    "    try:\n",
    "        author_data.iloc[i, author_data.columns.get_loc('last_known_institution')] = (list(author_data['last_known_institution'])[i]['display_name'])    \n",
    "    except:\n",
    "        author_data.iloc[i, author_data.columns.get_loc('last_known_institution')] = \"Unknown\"\n",
    "author_data = author_data.drop(columns = ['x_concepts']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55978ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4dc469",
   "metadata": {},
   "source": [
    "## Retrieving Insitution Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312c3548",
   "metadata": {},
   "source": [
    "Create the institution list from the author data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c556851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "institutions_list = author_data['last_known_institution'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6640bf9e",
   "metadata": {},
   "source": [
    "Replace commas and spaces at the start to retrieve the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be899d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(institutions_list)):\n",
    "    institutions_list[i] = institutions_list[i].replace(',','')\n",
    "    institutions_list[i] = institutions_list[i].lstrip()\n",
    "    print(institutions_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f0cd6a",
   "metadata": {},
   "source": [
    "Create a dataframe and retrieve the institutions using OpenAlex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974ef4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "institution_df = pd.DataFrame()\n",
    "\n",
    "for i in range(len(institutions_list)):\n",
    "    try:\n",
    "        print('Retrieved:',institutions_list[i])\n",
    "        institution_information = requests.get(\n",
    "            'https://api.openalex.org/institutions?filter=display_name.search:'+institutions_list[i]\n",
    "        ).json()['results'][0]\n",
    "        current_institution = pd.DataFrame.from_dict(institution_information, orient='index')\n",
    "        current_institution = current_institution.transpose()\n",
    "        institution_df = institution_df.append(current_institution)\n",
    "    except:\n",
    "        print(\"Empty name\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc90683",
   "metadata": {},
   "source": [
    "Preprocess the institution data by:\n",
    "\n",
    "1. renaming\n",
    "2. find out the main research field\n",
    "3. replacing special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0da102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "institution_data = institution_df[['display_name', 'relevance_score', 'country_code', 'type', 'cited_by_count', 'x_concepts']]\n",
    "institution_data = institution_data.rename(columns= {'display_name' : 'institution_name', 'relevance_score': 'institution_relevance_score', 'cited_by_count': 'institution_cited_by_count', 'x_concepts' : 'institution_main_research_field'})\n",
    "\n",
    "# gain knowledge about the institutions main research field\n",
    "for i in range(len(institution_data)):\n",
    "    try:\n",
    "        institution_data.iloc[i, institution_data.columns.get_loc('institution_main_research_field')] = (list(institution_data['institution_main_research_field'])[i][0]['display_name'])    \n",
    "    except:\n",
    "        institution_data.iloc[i, institution_data.columns.get_loc('institution_main_research_field')] = \"Unknown\"\n",
    "\n",
    "institution_data = institution_data.reset_index()\n",
    "institution_data = institution_data.drop(columns = 'index')\n",
    "        \n",
    "institution_data.institution_name = institution_data.institution_name.str.replace('[^a-zA-Z]', ' ')\n",
    "institution_data.institution_name = institution_data.institution_name.str.replace('  ',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfbca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "institution_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20c17b9",
   "metadata": {},
   "source": [
    "## Combining the dataframes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006a2466",
   "metadata": {},
   "source": [
    "Combining the data was a time consuming task due to smaller errors and mistakes.\n",
    "1. taking the authors from the metadata and replace their special characters\n",
    "2. taking the authors from the retrieved authors to gain more knowledge about them\n",
    "3. compare lost data due to merges (e.g. missing values somewhere or wrong name alignments)\n",
    "    - 3.1 since the metadata is taken document wise, high amounts of authors could be lost. Then, more have to be retrived\n",
    "4. merging the data \n",
    "5. comparing lost data due to merges in terms of adding the institution\n",
    "6. merging the data again now containing information about the Article, Authors and Institutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ab4942",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#replace metadata authors \n",
    "metadata_authors = split_authors(500)#len(metadata))\n",
    "metadata_authors.author = metadata_authors.author.str.replace('  ',' ')\n",
    "metadata_authors['author'] = metadata_authors['author'].str.lstrip()\n",
    "metadata_authors.author = metadata_authors.author.str.replace('.', '')\n",
    "\n",
    "metadata_authors = metadata_authors.rename(columns={'author': 'display_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57796ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing double spaces and dots\n",
    "author_data.display_name = author_data.display_name.str.replace('.', '')\n",
    "author_data.last_known_institution = author_data.last_known_institution.str.replace('  ',' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01158af0",
   "metadata": {},
   "source": [
    "lost data due to name merges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c49aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db52c291",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_authors['display_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac17d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_data['display_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f91050",
   "metadata": {},
   "source": [
    "Lost data due to authors: eventually high if split_authors has a higher value than getAuthors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcd8b89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(list(set(metadata_authors['display_name']) - set(author_data['display_name'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba938ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging our dataframes\n",
    "\n",
    "combined_data = metadata_authors.merge(author_data, on = 'display_name', how = 'outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33498cea",
   "metadata": {},
   "source": [
    "lost data due to institution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f8251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(combined_data['last_known_institution']) - set(institution_data['institution_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afffc086",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data2 = combined_data.merge(institution_data, left_on = 'last_known_institution', right_on = 'institution_name', how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5c65cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_data2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232102ad",
   "metadata": {},
   "source": [
    "## Retrieving Journal information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a35ce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_list = combined_data['full'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900f9884",
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_df = pd.DataFrame()\n",
    "\n",
    "for i in range(len(journal_list)):\n",
    "    try:\n",
    "        print(journal_list[i])\n",
    "        journal_information = requests.get(\n",
    "            'https://api.openalex.org/venues?filter=display_name.search:'+journal_list[i]\n",
    "        ).json()['results'][0]\n",
    "        current_journal = pd.DataFrame.from_dict(journal_information, orient='index')\n",
    "        current_journal = current_journal.transpose()\n",
    "        journal_df = journal_df.append(current_journal)\n",
    "    except:\n",
    "        print(\"Empty name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e764b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_data = journal_df[['issn', 'display_name', 'publisher', 'relevance_score', 'cited_by_count', 'cited_by_count','x_concepts']]\n",
    "journal_data = journal_data.rename(columns = {'display_name':'journal_display_name', 'publisher': 'journal_publisher', 'relevance_score': 'journal_relevance_score', 'cited_by_count' : 'journal_cited_count', 'x_concepts' : 'main_research_field'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c708444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0cd864",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(journal_data)):\n",
    "    try:\n",
    "        journal_data.iloc[i, journal_data.columns.get_loc('main_research_field')] = (list(journal_data['main_research_field'])[i][0]['display_name'])    \n",
    "    except:\n",
    "        journal_data.iloc[i, journal_data.columns.get_loc('main_research_field')] = \"Unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1817c3e3",
   "metadata": {},
   "source": [
    "Merging the journal data now to our complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580d1cca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# replacing dots\n",
    "journal_data.journal_display_name = journal_data.journal_display_name.str.replace('.', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9019b2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(combined_data2['full']) - set(journal_data['journal_display_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8d8c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data3 = combined_data2.merge(journal_data, left_on = 'full', right_on = 'journal_display_name', how = 'outer')\n",
    "combined_data3 = combined_data3.loc[:,~combined_data3.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2956441c",
   "metadata": {},
   "source": [
    "### Our completed Dataframe consisting of: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285d517e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_data3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b7a866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_data3.to_csv('outer_full_dataframe_500_new.csv', index=False, header=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9 (default, Feb 18 2022, 07:45:33) \n[Clang 13.1.6 (clang-1316.0.21.2)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
